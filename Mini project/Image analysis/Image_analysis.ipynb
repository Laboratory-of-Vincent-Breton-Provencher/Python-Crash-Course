{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run this if you wish to acces the file by pairing with your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VyAC_23Ttwtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuroPy week 3: Image analysis mini project\n",
        "\n",
        "In this project, we will start with a short recording (about 60s) of calcium data recorded at 5 Hz in the forebrain of a larval zebrafish. The data has already been motion-corrected. The objectives here are to:\n",
        "- Import the data;\n",
        "- Segment neurons;\n",
        "- Extract signal.\n",
        "\n",
        "Some parts of the code are already written out for you to cover more ground and avoid too much repetition. You should however try your best to understand the parts that are already written out. The parts you have to fill are identified with **#TODO** or 'strings' with directions.\n",
        "\n",
        "Before you start, it is important to upload the [file](https://drive.google.com/drive/folders/1yp0ak9PFHiliCQ-yei5ri193AJheNp9f?usp=sharing) we will be using for this exercice. You need to download the file from Google Drive and upload it in the contents folder of this notebook.\n",
        "\n",
        "## 1. Importing modules\n",
        "\n",
        "Here are the modules necessary to complete the mini-project"
      ],
      "metadata": {
        "id": "9r4LG9FEPJur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_mxyDcSPD4_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import skimage\n",
        "import cv2\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save you some time, I wrote a simple function to calculate the autocorrelation of a signal. The concepts behind it are explore in the signal analysis mini project."
      ],
      "metadata": {
        "id": "bmDSYo4dr4dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_autocorrelations(signals):\n",
        "  '''\n",
        "  Compute the autocorrelation of an array of signals and returns and array with\n",
        "  the autocorrelation coefficient of each signal\n",
        "   '''\n",
        "  autocorrs = []\n",
        "  for signal in signals:\n",
        "    autocorrs.append(np.correlate(signal, signal)[0])\n",
        "  return np.array(autocorrs)"
      ],
      "metadata": {
        "id": "__dWnvXQr168"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importing Data\n",
        "\n",
        "The first step in any type of analysis is understanding the data we are given. In this case, you could open the file in ImageJ before loading it in Python, to see what you have to work with. The first step is to load the stack. The function **imread** of the package [skimage.io](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread) lets you do that."
      ],
      "metadata": {
        "id": "I3TZK9Hqi_mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: import the stack"
      ],
      "metadata": {
        "id": "k3nIs6HpI93-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few questions to answer:\n",
        "\n",
        "1. How many images are in the stack and what is the dimension of each image?\n",
        "      \n",
        "      Hint: It may be a good idea to inspect the shape of your result. How would you acces a single frame? How would you track the value of a single pixel for the whole recording?\n",
        "2. What data type are we dealing with?\n",
        "      \n",
        "      Hint: get the **data type** of a single pixel."
      ],
      "metadata": {
        "id": "XFjZfWJ-BaNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: inspect the data"
      ],
      "metadata": {
        "id": "XhnAioF-EENv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we are dealing with [Unsigned 16-bits](https://doc.embedded-wizard.de/uint-type) images, which means we can have values ranging from 0 to 65535. While we could work with these images, we can make our life easier by transforming our images to Unsigned 8-bits data (values from 0 to 255). To do  so, we would have to use the formula:\n",
        "$$ frame_{8bits} = \\frac{255\\times(frame_{16bits} - frame_{min})}{frame_{max}-frame_{min}}$$\n",
        "\n",
        "$frame_{8bits}$: resulting frame in 8-bits (2D numpy array)\n",
        "\n",
        "$frame_{16bits}$: resulting frame in 16-bits (2D numpy array)\n",
        "\n",
        "$frame_{max}$: maximum value from the 16-bits image (int)\n",
        "\n",
        "$frame_{min}$: minimum value from the 8-bits image (int)\n",
        "\n",
        "This formula will yield an image with 0 as the most dim pixel and 255 as the most intense pixel. If you are having trouble implementing the solution, consider these tips:\n",
        "\n",
        "1. You may want to **iterate** over every frame of your stack, apply the formula to the frame and store the result in a different array.\n",
        "2. Your second movie (in 8-bits) will be an array with the same **shape** as your original movie (in 16-bits)."
      ],
      "metadata": {
        "id": "PCJom3BkF5lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: apply the forumla to every frame of the stack to make it in 16 bits"
      ],
      "metadata": {
        "id": "csg5QOBsPDPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does a frame in 8-bits look different from a frame in 16-bits when using the **plt.imshow()** function? To do so, use the function plt.imshow() to display **a single frame** from both your datasets."
      ],
      "metadata": {
        "id": "wfD4CwrH-4ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax0,ax1) = plt.subplots(1,2)\n",
        "ax0.imshow('your 8bits-frame', cmap = 'gray')\n",
        "ax0.axis('off')\n",
        "ax0.set_title('8-bits frame')\n",
        "\n",
        "ax1.imshow('your 16bits-frame', cmap = 'gray')\n",
        "ax1.axis('off')\n",
        "ax1.set_title('16-bits frame')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1rI6Jx7VAQKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not really! While 16-bits will have a better 'color' depth, the difference here is hard to observe with our own eyes. We just wanted to do this step to make our life easier later. That being said, data with 16-bits images is more rich and I would not recommend down-sizing your data when doing analysis.\n",
        "\n",
        "**Note for the rest of the mini-project:**\n",
        "\n",
        "You are free to apply whatever parameters you judge best, but the idea at the end is to extract an interesting timeseries. Consequently, the neurons that are shown in the zoom-in below show a somewhat interesting activity, so I would encourage that you keep in mind that these neurons should be included in your segmentation."
      ],
      "metadata": {
        "id": "X41sF-6PAxZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "film_8b = # TO-DO: insert here the name of your 8-bits movie variable\n",
        "\n",
        "fig, (ax0,ax1) = plt.subplots(1,2)\n",
        "\n",
        "ax0.imshow(film_8b[0], cmap = 'gray')\n",
        "ax0.hlines([50,80],175,230,color='red',ls='--')\n",
        "ax0.vlines([175,230],50,80,color='red',ls='--')\n",
        "ax0.axis('off')\n",
        "ax0.set_title('ROI')\n",
        "\n",
        "ax1.imshow(film_8b[0,50:80,175:230],cmap='gray')\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Zoomed')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yq_1cfugWTG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Thresholding\n",
        "\n",
        "The idea of the mini-project is to retrieve signal from our stack. To get our neuron's activity, we must first segment them. Before segmentation, however, comes the step of thresholding. Thresholding lets you get a binary image with everything with an intensity below a threshold as 0s everything above as 1s. The first step is to do a projection of our film. The two different types of projection we might be interested in will be the average projection and the maximum projection:\n",
        "\n",
        "\n",
        "Do both projections and display them. What do you notice?\n",
        "\n",
        "**Hint**: Is there a parameter of [numpy functions](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) that could help you, considering your stack is  loaded as matrix of dimensions (number of frames, x pixels, y pixels)?"
      ],
      "metadata": {
        "id": "CmKE6u3sjz4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_im = # TO DO: calculate the average projection\n",
        "max_im = # TO DO: calculate the maximum projection\n",
        "\n",
        "fig, (ax0,ax1) = plt.subplots(1,2)\n",
        "ax0.imshow(average_im, cmap = 'gray')\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Average projection')\n",
        "\n",
        "ax1.imshow(max_im, cmap = 'gray')\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Maximum projection')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_NtGzhBXJTh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Average projection**: Will help you see neurons that fired during the film, but also the ones that were bright the whole time. This method will also let you minimize the impact of noise and motion. You may loose neurons that do not fire during the acquisition.\n",
        "- **Maximum projection**: Will help you see everything. Sensitive to motion artifacts.\n",
        "\n",
        "Keeping in mind that thresholding is our goal, it should appear that the average projection is the way to go here. Display the histograms of pixel values to see how they are distributed."
      ],
      "metadata": {
        "id": "m18xBy63HMc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(max_im.flatten(),bins=25,log=True,color='green',label='Max projection')\n",
        "plt.hist(average_im.flatten(),bins=25,log=True,color='mediumblue',alpha=0.8,label='Average projection')\n",
        "plt.legend()\n",
        "plt.ylabel('Number of pixels (log)')\n",
        "plt.xlabel('Value of pixels (-)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DPzrjea9LozJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the maximum projection really seems harder to work with than the average projection. Let's keep working with the average projection.\n",
        "\n",
        "#### Manual threshold\n",
        "\n",
        "The first option when doing thresholding is choosing a threshold manually. Choose a threshold and apply it to your image.\n",
        "\n",
        "**Hint:** You can do the following operation with arrays\n",
        "        \n",
        "          array2 = array1 > value\n",
        "\n",
        "This will give an array2 with the same size as array1. The values in this array will be True if the condition is respected and False if it is not. You can then use\n",
        "\n",
        "        array2 = array2.astype(int)\n",
        "\n",
        "To replace the Trues with 1s and the Falses with 0s and obtain a binary image."
      ],
      "metadata": {
        "id": "QqenVpERI5kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th = # TO DO: choose your threshold\n",
        "\n",
        "binary = # TO DO: apply the threshold to your image\n",
        "\n",
        "\n",
        "plt.title('Manual threshold')\n",
        "plt.imshow(average_im,cmap='gray')\n",
        "plt.imshow(binary,alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UEmAKO2bK-4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that is probably not the best way to go. Another way to find a threshold is to let python calculate it. Here, you may want to use the [cv2.threshold](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html) method for simple thresholding, you should try different thresholds to see the one you like the most. Here are different thresholds that  are available to use:\n",
        " - cv2.THRESH_OTSU\n",
        " - cv2.THRESH_TRIANGLE\n",
        "\n",
        "It is possible to apply a multiplication factor to the value of the threshold to make it more or less harsh. Re-use the same logic as earlier to apply the threshold to your image."
      ],
      "metadata": {
        "id": "-e0cIDN4KaMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: calculate the threshold using the cv2.threshold method\n",
        "binary = # TO DO: apply the threshold (with or without factor) to your image\n",
        "\n",
        "plt.title('CV2 threshold')\n",
        "plt.imshow(average_im,cmap='gray')\n",
        "plt.imshow(binary,alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ue07BCdpLk-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it is possible to obtain similar results in a more rigourous manner. We now have a first draft of binary image. As you can see, some neurons touch, and some neurons just appear as small blobs."
      ],
      "metadata": {
        "id": "WGtAZ-D7LbQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax0,ax1) = plt.subplots(1,2)\n",
        "\n",
        "ax0.imshow(average_im[250:300,300:350],cmap='gray')\n",
        "ax0.imshow(binary[250:300,300:350],alpha=0.6)\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Merged neurons')\n",
        "\n",
        "ax1.imshow(average_im[375:425,290:340],cmap='gray')\n",
        "ax1.imshow(binary[375:425,290:340],alpha=0.6)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Small blobs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8BiwXk5RL4pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thankfully, the module OpenCV (here imported as cv2) lets us peform many oprations on our binary images. The first thing we could try is an [erosion](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb). This operation keeps the minimal value in a specified radius around each pixel. It will take out a layer around each blob and eliminate smaller ones. What we want here is to eliminate as many small blobs as possible without losing our interesting neurons."
      ],
      "metadata": {
        "id": "dmW3Kw6RPsbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "erosion_radius = # TO DO: Choose erosion radius\n",
        "eroded = # TO DO: Use cv2 to do an erosion to your image\n",
        "\n",
        "fig, (ax0,ax1,ax2) = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "ax0.imshow(average_im,cmap='gray')\n",
        "ax0.imshow(eroded,alpha=0.5)\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Erosion')\n",
        "\n",
        "ax1.imshow(average_im[250:300,300:350],cmap='gray')\n",
        "ax1.imshow(eroded[250:300,300:350],alpha=0.5)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Merged neurons')\n",
        "\n",
        "ax2.imshow(average_im[375:425,290:340], cmap='gray')\n",
        "ax2.imshow(eroded[375:425,290:340], alpha=0.5)\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Small blob')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S7gud0Q7lMnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we did get rid of our small blobs, we somewhat lost the shap of our interesting neurons. We should try to undo the effect of erosion on our bigger blobs to retrieve the original shape."
      ],
      "metadata": {
        "id": "gDt3rw_CpInx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dilation is the operation contrary to the erosion. It is done with a [function by OpenCV](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c).\n",
        "It will choose the maximum intensity vlaue in a specified radius around each pixel. Here, you can use it to obtain your original image-ish, without the small blobs.\n",
        "\n",
        "What you want to do here is find an appropriate dilation radius that let you segment as much of your neurons as possible, withouth them being too big. As the structure is the same for erosion and dilation, you only need to choose an appropriate radius."
      ],
      "metadata": {
        "id": "8aPFB1E0VM_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dilation_radius = # TO DO: choose a dilation radius\n",
        "\n",
        "dilated =  cv2.dilate(eroded.astype('uint8'),np.ones((dilation_radius,dilation_radius)))\n",
        "\n",
        "fig, (ax0,ax1,ax2) = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "ax0.imshow(average_im,cmap='gray')\n",
        "ax0.imshow(dilated,alpha=0.5)\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Dilation')\n",
        "\n",
        "ax1.imshow(average_im[250:300,300:350],cmap='gray')\n",
        "ax1.imshow(dilated[250:300,300:350],alpha=0.5)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Merged neurons')\n",
        "\n",
        "ax2.imshow(average_im[375:425,290:340], cmap='gray')\n",
        "ax2.imshow(dilated[375:425,290:340], alpha=0.5)\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Small blob')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5ZXpg_sEnCd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we've got a good binary image with some interesting neurons, we can move on to segmentation."
      ],
      "metadata": {
        "id": "XywcJW6rWexE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Segmentation using Opencv\n",
        "\n",
        "This is a very basic example of segmentation that could be used on images where neurons are sparse and big. More complex packages and tools for segmetation, like [Cellpose](https://www.cellpose.org/) or [Suite2p](https://www.suite2p.org/) should be looked into for more complex situations. This pipeline aims to give a good idea of the different operations available to do simple segmentation.\n",
        "\n",
        "The first tool we can use is OpenCV's [connecteComponentsWithStats](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga107a78bf7cd25dec05fb4dfc5c9e765f) function. This will let us separated ans label our different blobs. As OpenCV's documentation isn't the easiest to read, here is the bottom line:\n",
        "\n",
        "      cv2.connectedComponentsWithStats(input_image(type:uint8)) -> returns: (totalLabels, labelIds, stats, centroid)\n",
        "      totalLabels: Number of regions\n",
        "      labelIds: array of the size of the image where the value represent the number of the label (0=No label)\n",
        "      stats: stats computed (look at the parameter stats in the documentation for syntax)\n",
        "      centroid: centroid of each region\n",
        "\n",
        "The first thing we might want to do is display our image and look at the size of our regions. In the cell below:\n",
        "\n",
        "1. Use the cv2.connectedComponentWitStats function to do a first round of segmentation.\n",
        "2. Find the right way to retrieve the area of your regions using the right output and [structure](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#gac7099124c0390051c6970a987e7dc5c5).\n",
        "3. Extract your labelled image and assign it to a variable (for later use)"
      ],
      "metadata": {
        "id": "ISvJ6Bh1sysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: do the segmentation and fill the imshow and hist functions below:\n",
        "\n",
        "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10,5))\n",
        "ax0.imshow(\"Your labelled image\", cmap='nipy_spectral')\n",
        "ax0.set_title(\"Segmented image\")\n",
        "ax0.axis('off')\n",
        "\n",
        "ax1.hist(\"Your sizes\",color = 'green')\n",
        "ax1.set_xlabel('Size')\n",
        "ax1.set_ylabel('Region count')\n",
        "ax1.set_title('Distribution of sizes')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8CUbnfHj0Y6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fun fact**: everything set at 0 will also be considered a blob and will always be considered the blob 0. Thus, the region 0 in your data set iis representative of your whole background.\n",
        "\n",
        "Considering this, you should not be seeing only 2 bars in your histogram and the maximum size should be located at around 350."
      ],
      "metadata": {
        "id": "vOW_EPTMo-NP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From there, it could be interesting to filter our data according to size, as the neurons in our image have similar sizes. In our case, regions that are too big may be neurons that are merged and regions that are too small may be neurons that just aren't bright enough. In both cases, we do not necessarily want to keep them in our analysis. In the cell below, you should:\n",
        "\n",
        "1. Choose minimum and maximum sizes for your region based on your histogram above\n",
        "2. Complete the for-loop. The goal of this loop is to iterate over all your regions (except region 0) , check"
      ],
      "metadata": {
        "id": "kql9fTg22aG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_size = # TO DO: find a value\n",
        "max_size = # TO DO: find a value\n",
        "pre_filtering = # TO DO: assign to this variable the labelled image found above\n",
        "\n",
        "# Creating a blank image of the right size\n",
        "post_filtering = np.zeros(pre_filtering.shape)\n",
        "\n",
        "for i in range(\"your variable containing the number of labels\"):\n",
        "  if 'check whether the size of the blob is between min and max value':\n",
        "    post_filtering[pre_filtering == i] = 255 # writing the blob in the image\n",
        "\n",
        "# Another round of segmentation over the filtered image\n",
        "\n",
        "analysis = cv2.connectedComponentsWithStats(post_filtering.astype('uint8'))\n",
        "(totalLabels, label_ids, values, centroid)  = analysis\n",
        "post_filtering = np.copy(label_ids)\n",
        "\n",
        "fig, (ax0,ax1) = plt.subplots(1,2)\n",
        "ax0.imshow(pre_filtering, cmap='nipy_spectral')\n",
        "ax0.set_title(\"Original\")\n",
        "ax0.axis('off')\n",
        "\n",
        "ax1.imshow(post_filtering, cmap='nipy_spectral')\n",
        "ax1.set_title(\"After filtering\")\n",
        "ax1.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hxAi_Qnk2Zr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we ant to use the **centroids** we found to ensure that these neurons are really located on our original image. Here, you must find the right way to display the centroids you found in the cell above"
      ],
      "metadata": {
        "id": "fXbFzBda4LPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(average_im,cmap='gray')\n",
        "plt.scatter(\"centroid's first coordinate\", \"centroid's second coordinate\", marker = 'x', color = 'red')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aEd2zM2RyrPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Extracting timeseries\n",
        "\n",
        "Now is the time to extract timeseries from our segmentation. This is the point where we bring back our stack from the beginning, merge it with our segmentation and find neuronal activity.\n",
        "\n",
        "If you are stuck, try considering these tips:\n",
        "1. You want to iterate over your labels and get a mask of your region label (which will be an array of the size of one frame with 1s where the neuron is and 0s everywhere else).\n",
        "2. You want to apply this mask to everyframe of your stack (remember that you can multiply python arrays). From this point you have a stack with your fluorescence values only for your neuron. You might want to extract the mean, or the sum of fluorescence for all your pixels to get a single value at every time point of your stack."
      ],
      "metadata": {
        "id": "M70poC026sEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To do: extract your timeseries from your stack"
      ],
      "metadata": {
        "id": "wVIzbQkCy2vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many ways to display our timeseries. Here are two ways. You can change the slicing of the timeseries variable to obtain a better view. Before plotting, timseries are sorted according their autocorrelation to facilitate observations."
      ],
      "metadata": {
        "id": "MHhgJ6-I8G4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries = np.array(timeseries)\n",
        "correlations = np.argsort(compute_autocorrelations(timeseries))\n",
        "timeseries_sorted = timeseries[correlations]\n",
        "\n",
        "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(8,4))\n",
        "\n",
        "h = 0\n",
        "for ts in timeseries_sorted[:]: # You can change the slicing here\n",
        "  ax0.plot(ts - h, color = 'green')\n",
        "  h +=0.03\n",
        "\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Plotted timeseries')\n",
        "\n",
        "ax1.imshow(timeseries, cmap = 'hot')\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Drawn timeseries')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EhfxIljjK-ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the imshow function is not the best ways, as most our neurons have ugly traces, so we might want to use a zoomed version of the plotted timeseries. Let's look at three different traces"
      ],
      "metadata": {
        "id": "qzfnx0E-tQqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,3))\n",
        "plt.plot(timeseries_sorted[1], color='green')\n",
        "plt.plot(timeseries_sorted[5], color='purple')\n",
        "plt.plot(timeseries_sorted[-5], color='navy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ir8-Ar5sLIis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your segmentation is the same as mine's, these three traces should be somewhat interesting. Let's write their data in a dictionary."
      ],
      "metadata": {
        "id": "OW5g2Qz8wHa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interesting_ids = [1,5,-5]\n",
        "my_neurons = {'centroids':[],'timeseries':[]}\n",
        "\n",
        "for interesting_id in interesting_ids:\n",
        "  neuron_id = correlations[interesting_id] # finding what is the neuron's label\n",
        "  my_neurons['centroids'].append(centroid[neuron_id + 1]) # finding its centroid (we need to do +1 as the centroid was found before removing the region 0)\n",
        "  my_neurons['timeseries'].append(timeseries[neuron_id]) # getting the timeseries"
      ],
      "metadata": {
        "id": "w5xTABIIT_T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(12,4))\n",
        "\n",
        "ax0.imshow(average_im,cmap='gray')\n",
        "ax0.scatter(my_neurons['centroids'][0][0],my_neurons['centroids'][0][1],color='green',marker='x')\n",
        "ax0.scatter(my_neurons['centroids'][1][0],my_neurons['centroids'][1][1],color='purple',marker='x')\n",
        "ax0.scatter(my_neurons['centroids'][2][0],my_neurons['centroids'][2][0],color='navy',marker='x')\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Neuron positions')\n",
        "\n",
        "ax1.plot(my_neurons['timeseries'][0], color='green')\n",
        "ax1.plot(my_neurons['timeseries'][1], color='purple')\n",
        "ax1.plot(my_neurons['timeseries'][2], color='navy')\n",
        "ax1.set_xlabel('Time (s)')\n",
        "ax1.set_ylabel('Fluorescence (-)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qZiljHzXfjb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving data\n",
        "\n",
        "Your almost done! Your last job will be to save the data in a .csv file. Using a function from [pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html).\n",
        "\n",
        "The data is in a dictionary assigned to the name my_neurons."
      ],
      "metadata": {
        "id": "nG0P7CBSbQIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: save your dictionary of data in a csv file"
      ],
      "metadata": {
        "id": "uz1kKhhLb3MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (extra) 6. Segmentation using skimage\n",
        "\n",
        "Segmentation can also be done using the package skimage. The code is not so easy to do, so most of it is writtent out for you, what you must do is feed the code the right image and play with the MIN_DISTANCE parameter to find  goog segmentation. The code will find local maxima in the image and perform segmentation with a consideration for these local maxima."
      ],
      "metadata": {
        "id": "FQeMLKanj02m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_DISTANCE = # TO DO: find a good value for the minimal distance parameters.\n",
        "image = # TO DO: assign to this variable the image you wish to segment. It should be a binary image.\n",
        "\n",
        "labeled_cells = skimage.measure.label(image)\n",
        "distance = scipy.ndimage.distance_transform_edt(image)\n",
        "\n",
        "local_max_coords = skimage.feature.peak_local_max(distance, min_distance=MIN_DISTANCE)\n",
        "local_max_mask = np.zeros_like(distance, dtype=bool)\n",
        "local_max_mask[tuple(local_max_coords.T)] = True\n",
        "\n",
        "markers = skimage.measure.label(local_max_mask)\n",
        "segmented_cells = skimage.segmentation.watershed(-distance, markers, mask=image)"
      ],
      "metadata": {
        "id": "n30Bm5pXfogh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print/Display different parts of the code above here to understand what each item is"
      ],
      "metadata": {
        "id": "ggjJJ524UnFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, replace the elements in the imshow and scatter functions to display a map with labeled centroids and another one of the differen regions found. This is where you can verify whether the MIN_DISTANCE parameter you chose was appropriate or not."
      ],
      "metadata": {
        "id": "QKIqKL1gUmUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax0, ax1) = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "ax0.imshow(average_im, cmap='gray')\n",
        "ax0.scatter(local_max_coords[:, 1], local_max_coords[:, 0], marker='x', color='r')\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Centroids of segmentation')\n",
        "\n",
        "ax1.imshow(segmented_cells, cmap='nipy_spectral')\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Segmentation')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kNVToBxhk7Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about our merged neurons from the other example? Did the local maximum algorithm help seperate neurons that are close by?"
      ],
      "metadata": {
        "id": "wGeRkQnVVB0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "ax0.imshow(average_im,cmap='gray')\n",
        "ax0.imshow(segmented_cells,cmap='nipy_spectral',alpha=0.5)\n",
        "ax0.axis('off')\n",
        "ax0.set_title('Segmentation')\n",
        "\n",
        "ax1.imshow(average_im[250:300,300:350],cmap='gray')\n",
        "ax1.imshow(segmented_cells[250:300,300:350],cmap='nipy_spectral',alpha=0.8)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Merged neurons')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MbGWTDaxT9a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it somewhat succeeded, but isn't perfect. While it is better than simple segmentation, more complex algorithms are needed to segment our neurons.\n",
        "\n",
        "#### Extracting timeseries\n",
        "\n",
        "You can now adjust the code you made earlier to extract your timeseries and apply it to your new segmentation"
      ],
      "metadata": {
        "id": "5_JJVfnOV0J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: extract the timeseries of your neurons"
      ],
      "metadata": {
        "id": "HsTouYB-popz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display our timeseries!"
      ],
      "metadata": {
        "id": "PCVC0WT0y3wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries = np.array(timeseries)\n",
        "correlations = np.argsort(compute_autocorrelations(timeseries))\n",
        "timeseries_sorted = timeseries[correlations]\n",
        "\n",
        "h = 0\n",
        "plt.figure(figsize=(3,5))\n",
        "for ts in timeseries_sorted[:]:\n",
        "  plt.plot(ts - h, color = 'green')\n",
        "  h +=0.02\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dHMsDXccrqtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain similarily the same timeseries, using another method!"
      ],
      "metadata": {
        "id": "pxdvSfMVy9gP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this mini-project, you:\n",
        "- Imported data and played with data types\n",
        "- Thresholded images and played with binary images\n",
        "- Segmented neurons\n",
        "- Extracted timseries\n",
        "\n",
        "As mentioned earlier, this is not the most robust image segmentation, but it gives a good idea  of the operations available to do in Python.\n",
        "\n",
        "\n",
        "\n",
        "This Notebook was created and the data was acquired by Sandrine Poulin. Please do not share notebook or data without my permission. If you have any questions, you can always contact me (sandrine.poulin.3@ulaval.ca)"
      ],
      "metadata": {
        "id": "vXvXj52RzDS6"
      }
    }
  ]
}